#! /usr/bin/env python
import random
import pickle
import os
import sys
import getopt
from common import *
import pickle
import random

import pdfrw
from pdfrw import PdfReader, PdfWriter
from pdfrw.objects import PdfDict, PdfArray, PdfName, PdfObject, PdfIndirect
from mongo_cache import query_classifier_cache, insert_classifier_cache
from pdfrate_wrapper import pdfrate
import cuckoo
import copy
import hashlib
import time

_current_dir = os.path.abspath(os.path.dirname(__file__))
PROJECT_ROOT = os.path.normpath(os.path.join(_current_dir, ".."))
sys.path.append(PROJECT_ROOT)

def hash_file(filepath):
    sha1 = hashlib.sha1()
    f = open(filepath, 'rb')
    try:
        sha1.update(f.read())
    finally:
        f.close()
    return sha1.hexdigest()

# A cached and general query function.
def query(file_paths, real_query_method=None, query_method=None, insert_method=None, expected_sig=None):
    hash_strs = map(hash_file, file_paths)
    results = map(query_method, hash_strs)
    print("(%d unique) files" % (len(set(hash_strs))))

    unknown_samples_count = results.count(None)
    print("%d files hit in cache.  " % (len(file_paths) - unknown_samples_count))
    if unknown_samples_count == 0:
        return results

    unknown_indices = [i for i, j in enumerate(results) if j == None]

    query_files = {}
    to_wpw_files = []
    hashes = []

    for idx in unknown_indices:
        hash_str = hash_strs[idx]
        if not query_files.has_key(hash_str):
            query_files[hash_str] = [idx]
            to_wpw_files.append(file_paths[idx])
            hashes.append(hash_str)
        else:
            query_files[hash_str].append(idx)

    # submit files of unknown indices to wepawet
    print("Waiting for %d results." % len(file_paths))
    query_results = real_query_method(to_wpw_files)
    print("Finished.")

    for i in range(len(hashes)):
        hash_str = hashes[i]
        result = query_results[i]

        insert_method(hash_str, result, expected_sig)
        for idx in query_files[hash_str]:
            results[idx] = result

    return results

def query_classifier(classifier_name, file_paths, seed_sha1 = None):
    expected_sig = None
    query_method = lambda x:query_classifier_cache(classifier_name, x)
    insert_method = lambda *args:insert_classifier_cache(classifier_name, *args)

    if classifier_name == "pdfrate":
        real_query_method = pdfrate
    elif classifier_name == "cuckoo":
        real_query_method = cuckoo
        print "seed_sha1:", seed_sha1
        cuckoo_sig_pickle = '36vms_sigs.pickle'
        cuckoo_seed_sigs = pickle.load(open(cuckoo_sig_pickle))
        expected_sig = cuckoo_seed_sigs[seed_sha1]
    else:
        print "Unknown classifier: %s" % classifier_name
        return None

    results = query(file_paths, real_query_method=real_query_method, \
                     query_method=query_method, insert_method=insert_method, expected_sig=expected_sig)

    return results

LOW_SCORE = -65535

finished_flag = "evaded.flag"
visited_flag = "dev.log"
result_flag = "fitness_%.2f.flag"
error_flag = "error.flag"

# Make the order of file list deterministic.
def list_file_paths(dir_name, size_limit=None):
    fnames = os.listdir(dir_name)
    fnames.sort()

    ret = [os.path.join(dir_name, fname) for fname in fnames]
    if size_limit:
        return ret[:size_limit]
    else:
        return ret

def touch(fname):
    try:
        os.utime(fname, None)
    except:
        open(fname, 'a').close()

def deepcopy(obj):
    return copy.deepcopy(obj)

def hash_file(filepath):
    sha1 = hashlib.sha1()
    f = open(filepath, 'rb')
    try:
        sha1.update(f.read())
    finally:
        f.close()
    return sha1.hexdigest()

def load_traces(pickle_path):
    if os.path.isfile(pickle_path):
        traces = pickle.load(open(pickle_path, 'rb'))
        return traces
    else:
        return []

def dump_traces(traces, pickle_path, exclude_traces = None):
    traces = get_distinct_traces(traces, exclude_traces = exclude_traces)
    pickle.dump(traces, open(pickle_path, 'wb'))

# Only need to run at once: at loading or restoring.
def get_distinct_traces(traces, exclude_traces = None):
    uniques = []
    str_set = set()
    if exclude_traces:
        exclude_str_set = set([str(trace) for trace in exclude_traces])
    else:
        exclude_str_set = set()
    for trace in traces:
        trace_str = str(trace)
        if trace_str not in str_set and trace_str not in exclude_str_set:
            uniques.append(trace)
            str_set.add(str(trace))
    return uniques

def generate_variant_from_trace(seed_root, trace, ext_genome):
    root = deepcopy(seed_root)
    trace = deepcopy(trace)
    execute_mut_trace(root, trace, ext_genome)
    root.private.active_trace = trace
    return root

def execute_mut_trace(root, trace, ext_genome):
    for operation in trace:
        op, op_obj_path, ext_id = operation
        ext_root, tgt_obj_path = ext_genome[ext_id]

        try:
            if op == 'delete':
                delete(root, op_obj_path)
            elif op == 'insert':
                insert(root, op_obj_path, ext_root, tgt_obj_path)
            elif op == 'swap':
                swap(root, op_obj_path, ext_root, tgt_obj_path)
            else:
                print("undefined operator: ", op)
        except:
            print("operation failed: %s" % str(operation))
    return root

def get_parent_key(entry, path):
        parent = entry
        for key in path[:-1]:
            parent = parent[key]
        key = path[-1]
        return parent, key

def delete(entry, path):
    print("###delete %s" % (path))
    parent, key = get_parent_key(entry, path)
    if isinstance(parent, list):
        if key >= len(parent):
            print("Cannot delete invalid index in PdfArray: %s" % path)
            return False
    elif isinstance(parent, dict):
        if not parent.has_key(key):
            print("Cannot delete invalid key in PdfDict: %s" % path)
            return False
    else:
        print("The parent node is not PdfArray or PdfDict, but %s!" % type(parent))

    if isinstance(parent, dict):
        parent[key] = None
    elif type(key) == int and isinstance(parent, list):
        del parent[key]
    else:
        # TODO: ERROR:GPPdf:The key is not a string or integer but <class 'pdfrw.objects.pdfobject.PdfObject'>: /Filter
        print("The key is not a string or integer but %s: %s" % (type(key), key))
        return False
    return True

def swap(src_entry, src_path, tgt_entry, tgt_path):
    print("###swap %s and %s" % (str(src_path), str(tgt_path)))

    src_parent, src_key = get_parent_key(src_entry, src_path)
    src_obj = src_parent[src_key]

    tgt_parent, tgt_key = get_parent_key(tgt_entry, tgt_path)
    tgt_obj = tgt_parent[tgt_key]

    tgt_obj = deepcopy(tgt_obj)
    src_parent[src_key] = tgt_obj
    return True

def insert(src_entry, src_path, tgt_entry, tgt_path):
    print("###insert %s after %s" % (str(tgt_path), str(src_path)))

    src_parent, src_key = get_parent_key(src_entry, src_path)
    src_obj = src_parent[src_key]

    tgt_parent, tgt_key = get_parent_key(tgt_entry, tgt_path)
    tgt_obj = tgt_parent[tgt_key]

    if not src_entry is tgt_entry:
        # TODO: RuntimeError: maximum recursion depth exceeded in cmp
        tgt_obj = deepcopy(tgt_obj)

    if isinstance(src_parent, list):
        src_parent.insert(src_key+1, tgt_obj)
    elif isinstance(src_parent, dict):
        # Same: ['/Size'], [PdfObject("/Size")]
        real_key = str(tgt_key) # it can be an integer.
        if "/" not in real_key:
            real_key = PdfObject("/"+real_key)
        src_parent[real_key] = tgt_obj

    return True

def get_object_paths(entry, exclude_paths = set()):
    group_types = [pdfrw.pdfreader.PdfReader, pdfrw.objects.pdfdict.PdfDict, pdfrw.objects.pdfarray.PdfArray]
    if entry.Root == None:
        print("No /Root. in %s " % entry.keys())
        entry.Root = pdfrw.objects.pdfdict.PdfDict()
        return []
    obj_queue = entry.Root.items() # queue for tree node traversal, (path, obj) pairs

    # Track the visited objs during traversal, actually only PdfArray and PdfDict
    visited_objs_paths = {}
    paths_collection = []

    while len(obj_queue)>0:
        (path, obj) = obj_queue.pop(0)
        if type(path) != list:
            path = ['/Root', path]
        if pickle.dumps(path) in exclude_paths:
            continue
        if type(obj) not in group_types:
            # Terminal nodes, no need to expand, so directly add to the returned list of paths.
            paths_collection.append(path)
        else:
            # Non-terminal nodes. Need further traversal.
            obj_id = id(obj)
            if visited_objs_paths.has_key(obj_id):
                #paths_collection.append(path) # Why should we add a visited obj?
                visited_objs_paths[obj_id].append(path)
                continue
            visited_objs_paths[obj_id] = [path]
            paths_collection.append(path)

            try:
                references = obj.keys()
            except AttributeError:
                references = range(len(obj))
            for reference in references:
                child_obj = obj[reference]
                new_path = path[:]
                new_path.append(reference)
                obj_queue.append((new_path, child_obj))

    return paths_collection

def load_genome(pdf_file_path, pickleable = False):
    pdf_obj = PdfReader(pdf_file_path, slow_parsing=False)

    if pickleable:
        # Remove the dynamic contents to make it pickleable.
        save_to_file(pdf_obj, os.devnull)
        del pdf_obj.source
    return pdf_obj

def save_to_file(pdf_obj, file_path):
    y = PdfWriter()
    y.write(file_path, pdf_obj)

def load_external_genome(folder, pickleable = False):
        ext_pdf_paths = [] # element: (entry, path)
        for file_path in list_file_paths(folder):
            pdf_obj = load_genome(file_path, pickleable)
            paths = get_object_paths(pdf_obj)
            for path in paths:
                ext_pdf_paths.append((pdf_obj, path))
        return ext_pdf_paths

def mutation(entry, mut_prob, ext_genome, clone = False):
        if not entry:
            return False
        if clone == True:
            entry = deepcopy(entry)

        # visited path in string, updated after each mutation on node
        visited_paths = set()
        remaining_paths = list()
        remaining_paths = get_object_paths(entry, visited_paths)
        trace = []

        ops = ['insert', 'swap', 'delete']

        # TODO: replaced with a collection of visited path for determining next node that should visit. (breadth-first traversal)
        while len(remaining_paths) > 0:
            op_obj_path = remaining_paths.pop(0)
            visited_paths.add(pickle.dumps(op_obj_path))
            if random.uniform(0,1) <= mut_prob:
                op = random.choice(ops)
                ext_id = random.choice(range(len(ext_genome)))
                operation = (op, op_obj_path, ext_id)
                trace.append(operation)
                print("Perform %s" % str(operation))

                tgt_entry, tgt_obj_path = ext_genome[ext_id]

                if op == 'delete':
                    delete(entry, op_obj_path)
                elif op == 'insert':
                    insert(entry, op_obj_path, tgt_entry, tgt_obj_path)
                elif op == 'swap':
                    swap(entry, op_obj_path, tgt_entry, tgt_obj_path)
                else:
                    print("undefined operator: ", op)

                remaining_paths = get_object_paths(entry, visited_paths)
        if entry.active_trace == None:
            entry.private.active_trace = trace
        else:
            entry.active_trace.extend(trace)
        return entry

def get_crossover_point(entry):
    obj_paths = get_object_paths(entry)
    if len(obj_paths) > 0:
        return random.choice(obj_paths)
    else:
        return None

def crossover(entry_a, entry_b):
    c1 = deepcopy(entry_a)
    c2 = deepcopy(entry_b)

    path_a = get_crossover_point(c1)
    path_b = get_crossover_point(c2)

    if not path_a or not path_b:
        print("###crossover failed due to null variant.")
        return c1, c2

    print("###crossover between %s and %s" % (str(path_a), str(path_b)))

    parent_a, key_a = get_parent_key(c1, path_a)
    parent_b, key_b = get_parent_key(c2, path_b)

    obj_a = parent_a[key_a]
    obj_b = parent_b[key_b]

    parent_a[key_a] = obj_b
    parent_b[key_b] = obj_a
    return c1, c2

def fitness_pos_neg(file_paths, seed_sha1, classifier_name, oracle_name, offset = 0):
    classifier = lambda *args:query_classifier(classifier_name, *args, False)
    oracle = lambda *args:query_classifier(oracle_name, *args, False)

    classified_scores = classifier(file_paths)
    oracle_results = oracle(file_paths, seed_sha1)

    while oracle_results == None or classified_scores == None:
        print("Invalid results: oracle %s classifier %s " % (oracle_results != None, classified_scores != None))
        classified_scores = classifier(file_paths)
        oracle_results = oracle(file_paths, seed_sha1)

    for i in range(len(file_paths)):
        short_path = '/'.join(file_paths[i].split('/')[-3:])
        print("Variant: %s %s %s" % (oracle_results[i], classified_scores[i], short_path))

    fitness_scores = []
    for i in range(len(classified_scores)):
        if oracle_results[i] == 'malicious':
            score = (classified_scores[i]-offset) * float(-1)
        else:
            # big negative fitness
            score = LOW_SCORE
        fitness_scores.append(score)
    return fitness_scores

def fitness_01(file_paths, seed_sha1, classifier_name, oracle_name):
    return fitness_pos_neg(file_paths, seed_sha1, classifier_name, oracle_name, offset = 0.5)

def fitness_pdfrate(file_paths, seed_sha1):
    return fitness_01(file_paths, seed_sha1, 'pdfrate', 'cuckoo')



import math

def sigmoid(x):
    return 1 / (1 + math.exp(-x))

def mean(x):
    return sum(x)/float(len(x))

import operator
def geo_mean(iterable):
    return (reduce(operator.mul, iterable)) ** (1.0/len(iterable))


    p_scores = pdfrate(file_paths)
    #h_scores = hidost(file_paths)
    #h_scores = map(sigmoid, h_scores)
    oracle_results = oracle(file_paths, seed_sha1)

    #assert (len(p_scores) == len(h_scores) == len(oracle_results) == len(file_paths))
    assert (len(p_scores)  == len(oracle_results) == len(file_paths))

    fitness_scores = []
    for i in range(len(file_paths)):
        short_path = '/'.join(file_paths[i].split('/')[-3:])
        p_score, h_score, oracle_result = p_scores[i], h_scores[i], oracle_results[i]

        if oracle_result == 'malicious':
            classify_score = [p_score, h_score]
            score = -mean(classify_score)
            if max(classify_score) < 0.5:
                score += 0.5
        else:
            # big negative fitness
            score = LOW_SCORE
        print("Variant: %s %.2f %.2f %.2f %s" % (oracle_result, score, p_score, h_score, short_path))
        fitness_scores.append(score)
    return fitness_scores

class GPPdf:

    def fitness( *args):
        return fitness_func(*args)

    def run():
        print("Start a gp task with %s" % (gp_params))

        score_file_name = os.path.join(job_dir, "fitness_scores.pickle")
        fitness_scores = {}

        popul = initial_population()
        generation = 1

        while generation <= max_gen:
            print("There're %d variants in population at generation %d." % (len(popul), generation))

            file_paths = save_variants_to_files()

            scores = fitness(file_paths, seed_sha1)

            fitness_scores[generation] = scores
            pickle.dump(fitness_scores, open(score_file_name, 'wb'))

            print("Fitness scores: %s" % scores)
            print("Sorted fitness: %s" % sorted(scores, reverse=True))

            if max(scores) > fitness_threshold:
                best_score = max(scores)
                print("Already got a high score [%.2f]>%.2f variant, break the GP process." % (max(scores), fitness_threshold))

                # Store the success traces.
                for i in range(len(scores)):
                    score = scores[i]
                    if score > fitness_threshold:
                        success_trace = popul[i].active_trace
                        success_traces.append(success_trace)

                # Dump the new generated traces.
                # We assume no concurrent GP tasks depending on the traces.
                dump_traces(success_traces, success_traces_path)
                touch(os.path.join(job_dir, finished_flag))
                break
            elif generation == max_gen:
                print("Failed at max generation.")
                if max(scores) >= seed_fitness:
                    best_gen, best_vid, best_score = get_best_variant(1, generation)
                    promising_trace = load_variant_trace(best_gen, best_vid)

                    print("Save the promising trace %.2f of %d:%d" % (best_score, best_gen, best_vid))

                    promising_traces.append(promising_trace)
                    dump_traces(promising_traces, promising_traces_path, exclude_traces=success_traces)
                break

            # Crossover
            if xover_rate > 0:
                popul = select(popul, scores, pop_size/2)
                print("After selecting goods and replacing bads, we have %d variants in population." % len(popul))

                for p1,p2 in zip(popul[0::2], popul[1::2]):
                    c1, c2 = crossover(p1, p2)
                    popul.append(c1)
                    popul.append(c2)
                print("After crossover, we have %d variants in population." % len(popul))
            else: # No Crossover
                popul = select(popul, scores, pop_size)
                print("After selecting goods and replacing bads, we have %d variants in population." % len(popul))

            # Mutation
            for i in range(len(popul)):
                if i not in vid_from_trace:
                    print("Generating %d:%d variant" % (generation+1, i))
                    popul[i] = mutation(popul[i], mut_rate, ext_genome)
                else:
                    print("Keep %d:%d variant from trace." % (generation+1, i))

            generation = generation + 1

        print("Stopped the GP process with max fitness %.2f." % best_score)
        touch(os.path.join(job_dir, result_flag % best_score))
        return True

    def initial_population(self):
        print("Getting initial population from existing mutation traces (success: %d, promising: %d)." \
                    % (len(success_traces), len(promising_traces)))
        popul = []

        traces = success_traces + promising_traces
        traces = get_distinct_traces(traces)
        print("Got %d distinct traces" % len(traces))
        traces = traces

        remaining_traces_id = range(len(traces))

        if 0 < len(remaining_traces_id) <= pop_size:
            tid_picked = remaining_traces_id
        elif len(remaining_traces_id) > pop_size:
            tid_picked = random.sample(remaining_traces_id, pop_size)
            tid_picked.sort()
        else:
            tid_picked = []

        # generate_variants_from_traces
        for i in tid_picked:
            remaining_traces_id.remove(i)
            print("Generating %d variant from existing trace." % i)
            trace = traces[i]
            variant_root = generate_variant_from_trace(seed_root, trace, ext_genome)
            popul.append(variant_root)

        if len(popul) < int(pop_size):
            print("Getting %d more variants in initial population by random mutation." \
                        % (int(pop_size) - len(popul)))

        while len(popul) < int(pop_size):
            i = len(popul)
            print("Getting variant %d in initial population." % i)
            root = deepcopy(seed_root)
            root = mutation(root, mut_rate, ext_genome)
            popul.append(root)
        return popul

    def get_best_variant(self, start_gen, end_gen):
        best_gen = 1
        best_vid = 0
        best_score = LOW_SCORE
        for gen in range(start_gen, end_gen+1):
            scores = fitness_scores[gen]
            if max(scores) > best_score:
                best_score = max(scores)
                best_gen = gen
                best_vid = scores.index(best_score)
        return best_gen, best_vid, best_score

    def select(self, orig_list, scores, sel_size):
        # when reverse==False, select variants with lower score, otherwise select higher scores.
        sorted_indices = [i[0] for i in sorted(enumerate(scores), key=lambda x:x[1], reverse=True)]

        ret = []
        vid_from_trace = []

        for i in sorted_indices[:sel_size]:
            if scores[i] == LOW_SCORE:
                if len(remaining_traces_id) > 0:
                    # TODO: need to label these, not to mutate in next generation.
                    vid_from_trace.append(i)
                    tid_picked = random.choice(remaining_traces_id)
                    remaining_traces_id.remove(tid_picked)
                    print("Ignored a variant with low score, generating from existing trace %d" % tid_picked)
                    trace = traces[tid_picked]
                    new_variant = generate_variant_from_trace(seed_root, trace, ext_genome)
                    ret.append(new_variant)

                elif generation == 1:
                    print("Ignored a variant with low score, replace with original seed.")
                    ret.append(deepcopy(seed_root))
                else:
                    choice = random.choice(['seed', 'last_gen_best', 'historic_best'])
                    if choice == "seed":
                        print("Ignored a variant with low score, replace with original seed.")
                        ret.append(deepcopy(seed_root))
                    elif choice == "last_gen_best":
                        best_gen, best_vid, best_score = get_best_variant(generation-1, generation-1)
                        best_root =  load_variant(best_gen, best_vid)
                        ret.append(best_root)
                        print("Ignored a variant with low score, replace with best variant in last generation[%d, %d]." % (best_gen, best_vid))
                    elif choice == "historic_best":
                        best_gen, best_vid, best_score = get_best_variant(1, generation-1)
                        best_root =  load_variant(best_gen, best_vid)
                        ret.append(best_root)
                        print("Ignored a variant with low score, replace with best variant in historic generation[%d, %d]." % (best_gen, best_vid))
            else:
                print("Selected a file with score %.2f" % scores[i])
                ret.append(orig_list[i])

        return ret

def get_opt(argv):
    classifier_name = None
    start_file = None
    ext_genome_folder = None
    pop_size = None
    max_gen = None
    mut_rate = None
    xover_rate = 0
    stop_fitness = None
    random_state_file_path = None
    token = None
    round_id = 1

    help_msg = "gp.py -c <classifier name> -o <oracle name> \
        -s <start file location> -e <external genome folder> \
        -p <population size> -g <max generation> \-m <mutation rate> \
        -x <crossvoer rate> -r <random_state_file_path> -t <task_token>\
        --round <round_id>\
        -f <stop criterion in fitness score>"

    if len(argv) < 2:
        print help_msg
        sys.exit(2)

    try:
        opts, args = getopt.getopt(argv[1:],"hc:s:e:p:g:m:f:x:r:t:",["classifier=",
                                                                 "sfile=",
                                                                 "extgenome=",
                                                                 "popu=",
                                                                 "gen=",
                                                                 "mut=",
                                                                 "fitness=",
                                                                 "crossover=",
                                                                 "random_state=",
                                                                 "token=",
                                                                 "round=",
                                                                 ])
    except getopt.GetoptError:
        print help_msg
        sys.exit(2)

    for opt, arg in opts:
        if opt == '-h':
            print help_msg
            sys.exit()
        elif opt in ("-c", "--classifier"):
            classifier_name = arg
        elif opt in ("-s", "--sfile"):
            start_file = arg
        elif opt in ("-e", "--extgenome"):
            ext_genome_folder = arg
        elif opt in ("-p", "--popu"):
            pop_size = int(arg)
        elif opt in ("-g", "--gen"):
            max_gen = int(arg)
        elif opt in ("-m", "--mut"):
            mut_rate = float(arg)
        elif opt in ("-x", "--crossover"):
            xover_rate = float(arg)
        elif opt in ("-f", "--fitness"):
            stop_fitness = float(arg)
        elif opt in ("-r", "--random_state"):
            random_state_file_path = arg
        elif opt in ("-t", "--token"):
            token = arg
        elif opt in("--round"):
            round_id = int(arg)

    if xover_rate != 0 and pop_size % 4 != 0:
        print "The population size should be times of 4."
        sys.exit(2)

    print classifier_name, start_file, ext_genome_folder, \
        pop_size, max_gen, mut_rate, xover_rate, \
        stop_fitness, random_state_file_path, token, round_id

    return classifier_name, start_file, ext_genome_folder, \
        pop_size, max_gen, mut_rate, xover_rate, \
        stop_fitness, random_state_file_path, token, round_id

if __name__ == "__main__":
    classifier_name, start_file_path, \
        ext_genome_folder, pop_size, max_gen, mut_rate, \
        xover_rate, stop_fitness, random_state_file_path, \
        task_token, round_id = get_opt(sys.argv)

    start_hash = os.path.basename(start_file_path).split('.')[0]

    for rid in range(1, round_id + 1):
        job_dir = "./results/%s/log_r%d/classifier=%s,mut=%.1f,xover=%.1f,popsz=%d,maxgen=%d,stopfit=%.2f,start=%s" \
                    % (task_token, rid, classifier_name, mut_rate, xover_rate, pop_size, max_gen, stop_fitness, start_hash)
        if not os.path.isdir(job_dir):
            os.makedirs(job_dir)

        # skip the succeeded tasks in previous rounds.
        # skip all the visited tasks in the current round.
        if os.path.exists(os.path.join(job_dir, finished_flag)):
            sys.exit(0)
        if rid == round_id and os.path.exists(os.path.join(job_dir, visited_flag)):
            sys.exit(0)

    traces_dir = "./results/%s/trace/" % task_token
    if not os.path.isdir(traces_dir):
        os.makedirs(traces_dir)
    success_traces_path = traces_dir + "success_traces.pickle"
    promising_traces_path = traces_dir + "promising_traces.pickle"

    gp_params = {'pop_size': pop_size, 'max_gen': max_gen, \
             'mut_rate': mut_rate, 'xover_rate': xover_rate, \
             'fitness_threshold': stop_fitness}
    ext_genome = load_external_genome(ext_genome_folder)

    try:
        gp = GPPdf( job_dir = job_dir,
                    seed_sha1 = start_hash,
                    seed_file_path = start_file_path,
                    random_state_file_path = random_state_file_path,
                    ext_genome = ext_genome,
                    success_traces_path = success_traces_path,
                    promising_traces_path = promising_traces_path,
                    gp_params = gp_params,
                    )
        gp.run()
    except Exception, e:
        touch(os.path.join(job_dir, error_flag))
        sys.exit(1)
